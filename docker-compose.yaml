version: '3.8'

networks:
  mlops_network:
    driver: bridge

services:
  postgres:
    image: postgres:13
    container_name: postgres
    env_file: .env
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - ./postgres:/var/lib/postgresql/data
    networks:
      - mlops_network
    restart: always

  airflow-webserver:
    build: ./airflow
    image: custom-airflow:latest
    container_name: airflow-webserver
    env_file: .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AWS_ACCESS_KEY_ID=${MINIO_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${MINIO_SECRET_KEY}
      - MLFLOW_S3_ENDPOINT_URL=${MLFLOW_S3_ENDPOINT_URL}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./datasets:/opt/airflow/datasets
      - ./airflow/models:/opt/airflow/models
    ports:
      - "8080:8080"
    depends_on:
      - postgres
      - minio
    networks:
      - mlops_network
    command: ["airflow","webserver"]
    restart: always

  airflow-scheduler:
    build: ./airflow
    image: custom-airflow:latest
    container_name: airflow-scheduler
    env_file: .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AWS_ACCESS_KEY_ID=${MINIO_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${MINIO_SECRET_KEY}
      - MLFLOW_S3_ENDPOINT_URL=${MLFLOW_S3_ENDPOINT_URL}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./datasets:/opt/airflow/datasets
      - ./airflow/models:/opt/airflow/models
    depends_on:
      - postgres
      - minio
    networks:
      - mlops_network
    command: ["airflow","scheduler"]
    restart: always

  minio:
    image: minio/minio:latest
    container_name: minio
    env_file: .env
    environment:
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
    command: server /data --console-address ":9001"
    volumes:
      - ./minio:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - mlops_network
    restart: always

  mysql:
    image: mysql:8.0
    container_name: mysql
    command: --default-authentication-plugin=mysql_native_password
    env_file: .env
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - MYSQL_DATABASE=${MYSQL_DATABASE}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
    volumes:
      - ./mysql:/var/lib/mysql
    ports:
      - "3306:3306"
    networks:
      - mlops_network
    restart: always

  mlflow:
    build: ./mlflow
    image: custom-mlflow:latest
    container_name: mlflow
    env_file: .env
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_BACKEND_STORE_URI=mysql+pymysql://${MYSQL_USER}:${MYSQL_PASSWORD}@mysql:3306/${MYSQL_DATABASE}
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://mlflow
      - AWS_ACCESS_KEY_ID=${MINIO_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${MINIO_SECRET_KEY}
      - MLFLOW_S3_ENDPOINT_URL=${MLFLOW_S3_ENDPOINT_URL}
    volumes:
      - ./mlflow:/mlflow
    ports:
      - "5000:5000"
    depends_on:
      - mysql
      - minio
    networks:
      - mlops_network
    command: >
      mlflow server
      --backend-store-uri $${MLFLOW_BACKEND_STORE_URI}
      --default-artifact-root $${MLFLOW_DEFAULT_ARTIFACT_ROOT}
      --host 0.0.0.0
    restart: always

  inference:
    build: ./inference
    image: custom-inference:latest
    container_name: inference
    env_file: .env
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - AWS_ACCESS_KEY_ID=${MINIO_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${MINIO_SECRET_KEY}
      - MLFLOW_S3_ENDPOINT_URL=${MLFLOW_S3_ENDPOINT_URL}
    ports:
      - "8000:8000"
    depends_on:
      - mlflow
    networks:
      - mlops_network
    command: uvicorn main:app --host 0.0.0.0 --port 8000
    restart: always

  ui:
    build: ./ui
    image: custom-ui:latest
    container_name: ui
    env_file: .env
    ports:
      - "8503:8503"
    depends_on:
      - inference
    networks:
      - mlops_network
    command: streamlit run app.py --server.port 8503 --server.address 0.0.0.0
    restart: always

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    ports:
      - "9090:9090"
    depends_on:
      - inference
    networks:
      - mlops_network
    restart: always

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    env_file: .env
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - ./grafana:/var/lib/grafana
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    networks:
      - mlops_network
    restart: always

  locust:
    image: locustio/locust
    container_name: locust
    volumes:
      - ./locust:/mnt/locust
    ports:
      - "8089:8089"
    depends_on:
      - inference
    networks:
      - mlops_network
    command: locust -f /mnt/locust/locustfile.py --host=http://inference:8000
    restart: always

  jupyterlab:
    image: jupyter/base-notebook:latest
    container_name: jupyterlab
    env_file: .env
    volumes:
      - ./notebooks:/home/jovyan/work
    ports:
      - "8888:8888"
    depends_on:
      - airflow-webserver
      - airflow-scheduler
      - mlflow
    networks:
      - mlops_network
    restart: always

volumes:
  postgres:
  minio:
  mysql:






